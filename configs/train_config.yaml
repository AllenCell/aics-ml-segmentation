##########################################################################################################
# model settings
##########################################################################################################
model: 
  # REQUIRED PARAMETERS
  name: BasicUNet
  # number of input channels to the model
  in_channels: 1
  # number of output channels/ number of classes
  out_channels: 2
  # input patch size given to the network (adapt to fit in your GPU memory, generally bigger patches are better)
  # network output will be of the same size
  patch_size:    [26, 105,105] #[52, 210, 210]
  # number of dimensions in data
  dimensions: 3
  
  # OPTIONAL PARAMETERS - these can be left blank to use defaults
  norm: #'instance' # instance | batch |  defaults to batch
  act: #'ReLU6' # ReLU | LeakyReLU | PReLU | ReLU6, defaults to LeakyReLU
  features: #[32, 32, 64, 128, 512, 32] # list of 6 numbers,the first five specify the encoder feature sizes. The last value corresponds to the feature size after the last upsampling. defaults to [32, 32, 64, 128, 256, 32]
  dropout: #True # True | False, defaults to False
  
# path to save the checkpoint
checkpoint_dir: '/allen/aics/assay-dev/users/Benji/model_checkpoints/'
# path to latest checkpoint; if provided the training will be resumed from that checkpoint
resume: #'/allen/aics/assay-dev/users/Benji/model_checkpoints/checkpoint_epoch=199.ckpt'

##########################################################################################################
# training precedure setting
##########################################################################################################
# initial learning rate
learning_rate: 0.001
# weight decay
weight_decay: 0.005

# learning rate scheduler configuration, leave name blank to omit
scheduler:
  name: CosineAnnealingLR
  # whether to print updates when learning rate is adjusted
  verbose: True
  # scheduler parameters - these vary by the chosen scheduler
  mode: min
  T_max: 10

# max number of epochs
epochs: 200
# number of epoch to save the model 
save_every_n_epoch: 5
# number of gpus to use default is all available OPTIONAL
gpus: 1 # -1 or positive integer
# distributed backend, default is ddp if gpus > 1, else none OPTIONAL
dist_backend:  #ddp 

# OPTIONAL leave name blank to avoid using additional callbacks
callbacks:
  name: 
  # metric to monitor
  monitor: val_loss
  #how much monitored value has to change 
  min_delta: 0.05
  # how many epochs to wait before stopping
  patience: 10 
  verbose: True
  #whether to minimize or maximize monitored metric
  mode: min

# loss function configuration
loss:
  # loss function to be used during training
  name: GeneralizedDice
  # A manual rescaling weight given to each class's loss. Should be of length nclass
  loss_weight: [1, 1]
  # a target value that is ignored and does not contribute to the input gradient
  ignore_index: null



##########################################################################################################
# data loaders configuration
###########################################################################
loader:
  name: default
  # paths to the training datasets
  datafolder: '//allen/aics/assay-dev/users/Jianxu/data/training_assay_caax_cellmask/training_data/initial_caax_model_better_top'
  # number of batch in each training iteration (related to patch size and GPU memory)
  batch_size: 4
  # number of patches loaded to cache 
  PatchPerBuffer: 32
  # number of epoches for every time the patches in cache are cleared and resampled (smaller = heavier i/o, larger = higher chance of overfitting)
  epoch_shuffle: 27
  # number of workers for loading data in each training iteration
  NumWorkers: 8
  # Random rotation and random flip
  Transforms: ['RF', 'RR']

##########################################################################################################
# validation setting
##########################################################################################################
# evaluation metric configuration
validation:
  # the metric for validation 
  metric: default
  # how to make the validation set (only used if metric is not None)
  leaveout: [0]
  # the channel to extract from output tensors
  OutputCh: 1
  # how many iterations between validations
  validate_every_n_epoch: 1